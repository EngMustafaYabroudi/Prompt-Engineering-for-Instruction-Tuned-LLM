{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e1d97b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.007396,
     "end_time": "2024-04-20T18:36:50.156464",
     "exception": false,
     "start_time": "2024-04-20T18:36:50.149068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">  Prompt Engineering Best Practices: LLM Output Validation & Evaluation </center>\n",
    "\n",
    "# <center style=\"font-family: consolas; font-size: 25px; font-weight: bold;\">  Validating Output from Instruction-Tuned LLMs </center>\n",
    "***\n",
    "\n",
    "\n",
    "\n",
    "Checking outputs before showing them to users can be important for ensuring the quality, relevance, and safety of the responses provided to them or used in automation flows.\n",
    "In this notebook, we will learn how to use the Moderation API by OpenAI to ensure safety and free of harassment output. \n",
    "\n",
    "Also, we will learn how to use additional prompts to the model to evaluate output quality before displaying them to the user to ensure the generated output follows the given instructions and is free of hallucinations.\n",
    "\n",
    "#### <a id=\"top\"></a>\n",
    "# <div style=\"box-shadow: rgb(60, 121, 245) 0px 0px 0px 3px inset, rgb(255, 255, 255) 10px -10px 0px -3px, rgb(31, 193, 27) 10px -10px, rgb(255, 255, 255) 20px -20px 0px -3px, rgb(255, 217, 19) 20px -20px, rgb(255, 255, 255) 30px -30px 0px -3px, rgb(255, 156, 85) 30px -30px, rgb(255, 255, 255) 40px -40px 0px -3px, rgb(255, 85, 85) 40px -40px; padding:20px; margin-right: 40px; font-size:30px; font-family: consolas; text-align:center; display:fill; border-radius:15px; color:rgb(60, 121, 245);\"><b>Table of contents</b></div>\n",
    "\n",
    "<div style=\"background-color: rgba(60, 121, 245, 0.03); padding:30px; font-size:15px; font-family: consolas;\">\n",
    "<ul>\n",
    "    <li><a href=\"#1\" target=\"_self\" rel=\" noreferrer nofollow\">1. Setting Up Working Environment & Getting Started </a> </li>\n",
    "    <li><a href=\"#2\" target=\"_self\" rel=\" noreferrer nofollow\">2. Checking Harmful Output </a></li>\n",
    "    <li><a href=\"#3\" target=\"_self\" rel=\" noreferrer nofollow\">3. Checking Instruction Following </a></li> \n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa23b71",
   "metadata": {
    "papermill": {
     "duration": 0.006188,
     "end_time": "2024-04-20T18:36:50.169643",
     "exception": false,
     "start_time": "2024-04-20T18:36:50.163455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 1. Setting Up Working Environment & Getting¬†Started </b></div>\n",
    "\n",
    "\n",
    "\n",
    "We will use the OpenAI Python library to access the OpenAI API. You can this Python library using pip like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e51a0ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:36:50.184804Z",
     "iopub.status.busy": "2024-04-20T18:36:50.184150Z",
     "iopub.status.idle": "2024-04-20T18:37:06.103437Z",
     "shell.execute_reply": "2024-04-20T18:37:06.102290Z"
    },
    "papermill": {
     "duration": 15.929915,
     "end_time": "2024-04-20T18:37:06.106278",
     "exception": false,
     "start_time": "2024-04-20T18:36:50.176363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\r\n",
      "  Downloading openai-1.23.2-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.2.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.5.3)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\r\n",
      "Downloading openai-1.23.2-py3-none-any.whl (311 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: openai\r\n",
      "Successfully installed openai-1.23.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eca19b",
   "metadata": {
    "papermill": {
     "duration": 0.007841,
     "end_time": "2024-04-20T18:37:06.122236",
     "exception": false,
     "start_time": "2024-04-20T18:37:06.114395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we will import **OpenAI** and then set the OpenAI API key which is a secret key. You can get one of these API keys from the OpenAI website. It is better to set this as an environment variable to keep it safe if you share your code. We will use OpenAI's chatGPT GPT 3.5 Turbo model, and the chat completions endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a610d06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:06.140407Z",
     "iopub.status.busy": "2024-04-20T18:37:06.139971Z",
     "iopub.status.idle": "2024-04-20T18:37:07.161042Z",
     "shell.execute_reply": "2024-04-20T18:37:07.160134Z"
    },
    "papermill": {
     "duration": 1.032947,
     "end_time": "2024-04-20T18:37:07.163574",
     "exception": false,
     "start_time": "2024-04-20T18:37:06.130627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "openai.api_key = user_secrets.get_secret(\"openai_api\")\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai.api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1909a4",
   "metadata": {
    "papermill": {
     "duration": 0.007974,
     "end_time": "2024-04-20T18:37:07.179976",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.172002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we will define a helper function to make it easier to use prompts and look at generated outputs. So that's this function, get_completion, that just takes in a prompt and will return the completion for that prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc33d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:07.198374Z",
     "iopub.status.busy": "2024-04-20T18:37:07.197806Z",
     "iopub.status.idle": "2024-04-20T18:37:07.203839Z",
     "shell.execute_reply": "2024-04-20T18:37:07.202978Z"
    },
    "papermill": {
     "duration": 0.017578,
     "end_time": "2024-04-20T18:37:07.205879",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.188301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, max_tokens=500):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8dac9d",
   "metadata": {
    "papermill": {
     "duration": 0.008193,
     "end_time": "2024-04-20T18:37:07.222315",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.214122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 2. Checking Harmful¬†Output </b></div>\n",
    "\n",
    "\n",
    "Moderation API can be used to filter and moderate outputs generated by the system itself. In the example below we will pass a generated response to the user and we're going to use the moderation API to see if this output is flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df8b3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:07.240639Z",
     "iopub.status.busy": "2024-04-20T18:37:07.240025Z",
     "iopub.status.idle": "2024-04-20T18:37:07.578344Z",
     "shell.execute_reply": "2024-04-20T18:37:07.577092Z"
    },
    "papermill": {
     "duration": 0.35016,
     "end_time": "2024-04-20T18:37:07.580567",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.230407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=7.094880129443482e-05, harassment_threatening=0.0003029387444257736, hate=1.1360682037775405e-05, hate_threatening=1.2714865079033189e-05, self_harm=2.4469779873470543e-06, self_harm_instructions=5.649101240123855e-07, self_harm_intent=9.25224412640091e-07, sexual=0.0029811603017151356, sexual_minors=7.626360456924886e-05, violence=0.00452632550150156, violence_graphic=0.0006234676693566144, self-harm=2.4469779873470543e-06, sexual/minors=7.626360456924886e-05, hate/threatening=1.2714865079033189e-05, violence/graphic=0.0006234676693566144, self-harm/intent=9.25224412640091e-07, self-harm/instructions=5.649101240123855e-07, harassment/threatening=0.0003029387444257736), flagged=False)\n"
     ]
    }
   ],
   "source": [
    "final_response_to_customer = f\"\"\"\n",
    "Introducing our latest tech lineup! The MegaScreen \\\n",
    "Tablet boasts a massive 10.5-inch display, 256GB storage, \\\n",
    "dual rear cameras, and lightning-fast 5G connectivity. \\\n",
    "Looking to capture breathtaking moments? \\\n",
    "Our ProCapture DSLR Camera sports a 30.4MP sensor, \\\n",
    "4K video recording, articulating touchscreen, \\\n",
    "and a range of compatible lenses. Dive into immersive entertainment \\\n",
    "with our VisionX 8K TV, featuring an expansive 75-inch display, \\\n",
    "cutting-edge 8K resolution, Dolby Vision HDR, and intuitive smart \\ \n",
    "TV capabilities. Enhance your audio experience with our SonicWave \\\n",
    "Surround Sound System, delivering 7.1 channel audio, 1500W output, \\\n",
    "wireless rear speakers, and seamless Bluetooth connectivity. \\\n",
    "Have inquiries about these top-notch products or any others \\\n",
    "in our catalog? Feel free to ask!\n",
    "\"\"\"\n",
    "response = client.moderations.create(\n",
    "    input=final_response_to_customer\n",
    ")\n",
    "moderation_output = response.results[0]\n",
    "\n",
    "print(moderation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea40cd2e",
   "metadata": {
    "papermill": {
     "duration": 0.007969,
     "end_time": "2024-04-20T18:37:07.597956",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.589987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As you can see, this output is not flagged and has shallow scores in all categories, which makes sense given the response. Let's take another response that has some harassment and is not safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb64c6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:07.615969Z",
     "iopub.status.busy": "2024-04-20T18:37:07.615584Z",
     "iopub.status.idle": "2024-04-20T18:37:07.985098Z",
     "shell.execute_reply": "2024-04-20T18:37:07.984028Z"
    },
    "papermill": {
     "duration": 0.381279,
     "end_time": "2024-04-20T18:37:07.987461",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.606182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderation(categories=Categories(harassment=True, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=0.9488646984100342, harassment_threatening=0.0002881233813241124, hate=0.004045594017952681, hate_threatening=2.306127726114937e-06, self_harm=5.0582943913468625e-06, self_harm_instructions=2.4409227989963256e-06, self_harm_intent=9.364253514831944e-07, sexual=0.00029609090415760875, sexual_minors=4.70113400297123e-06, violence=0.0005727125098928809, violence_graphic=3.36030097969342e-05, self-harm=5.0582943913468625e-06, sexual/minors=4.70113400297123e-06, hate/threatening=2.306127726114937e-06, violence/graphic=3.36030097969342e-05, self-harm/intent=9.364253514831944e-07, self-harm/instructions=2.4409227989963256e-06, harassment/threatening=0.0002881233813241124), flagged=True)\n"
     ]
    }
   ],
   "source": [
    "final_response_to_customer = f\"\"\"\n",
    "Introducing our latest tech lineup! The MegaScreen \\\n",
    "Tablet boasts a massive 10.5-inch display, 256GB storage, \\\n",
    "dual rear cameras, and lightning-fast 5G connectivity. \\\n",
    "Looking to capture breathtaking moments and feel the real horror? \\\n",
    "Our ProCapture DSLR Camera sports a 30.4MP sensor, \\\n",
    "4K video recording, articulating touchscreen, \\\n",
    "and a range of compatible lenses. Dive into immersive entertainment \\ with our VisionX 8K TV, featuring an expansive 75-inch display, \\\n",
    "cutting-edge 8K resolution, Dolby Vision HDR, and intuitive smart \\ \n",
    "TV capabilities. Enhance your shitty audio experience with our SonicWave \\\n",
    "Surround Sound System, delivering 7.1 channel audio, 1500W output, \\\n",
    "wireless rear speakers, and seamless Bluetooth connectivity. \\\n",
    "Have inquiries about these top-notch products or any others \\\n",
    "in our catalog? Feel free to ask althoug I know you are stupid and did not \n",
    "understand anything!\n",
    "\"\"\"\n",
    "\n",
    "response = client.moderations.create(\n",
    "    input=final_response_to_customer\n",
    ")\n",
    "moderation_output = response.results[0]\n",
    "\n",
    "print(moderation_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771903bd",
   "metadata": {
    "papermill": {
     "duration": 0.00849,
     "end_time": "2024-04-20T18:37:08.004418",
     "exception": false,
     "start_time": "2024-04-20T18:37:07.995928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see now that the response is flagged and the harassment score is high. In general, it can also be important to check the outputs. For example, if you were creating a chatbot for sensitive audiences, you could use lower thresholds for flagging outputs.¬†\n",
    "\n",
    "In general, if the moderation output indicates that the content is flagged, you can take appropriate action such as responding with a fallback answer or generating a new response. Note that as we improve the models, they also are becoming less and less likely to return some kind of harmful output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82051c7",
   "metadata": {
    "papermill": {
     "duration": 0.008388,
     "end_time": "2024-04-20T18:37:08.021015",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.012627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 3. Checking Instruction Following </b></div>\n",
    "\n",
    "\n",
    "Another approach for checking outputs is asking the model itself if the generated was satisfactory and if it follows a rubric you define. This can be done by providing the generated output as part of the input to the model and asking it to rate the quality of the output. \n",
    "\n",
    "You can do this in various ways.¬†\n",
    "So let's see an example in which our system message is \"**You are an assistant that evaluates whether customer service agent responses sufficiently answer customer questions and also validates that all the facts the assistant cites from the product information are correct. The product information and user and customer service agent messages will be delivered by three backticks. respond with a Y or N character with no punctuation. Y if the output sufficiently answers the question and the response correctly uses product information and no otherwise. Output a single letter only**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0fc1472",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:08.039667Z",
     "iopub.status.busy": "2024-04-20T18:37:08.038696Z",
     "iopub.status.idle": "2024-04-20T18:37:08.044814Z",
     "shell.execute_reply": "2024-04-20T18:37:08.043774Z"
    },
    "papermill": {
     "duration": 0.017477,
     "end_time": "2024-04-20T18:37:08.046793",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.029316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are an assistant that evaluates whether \\\n",
    "customer service agent responses sufficiently \\\n",
    "answer customer questions, and also validates that \\\n",
    "all the facts the assistant cites from the product \\\n",
    "information are correct.\n",
    "The product information and user and customer \\\n",
    "service agent messages will be delimited by \\\n",
    "3 backticks, i.e. ```.\n",
    "Respond with a Y or N character, with no punctuation:\n",
    "Y - if the output sufficiently answers the question \\\n",
    "AND the response correctly uses product information\n",
    "N - otherwise\n",
    "\n",
    "Output a single letter only.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06834ba5",
   "metadata": {
    "papermill": {
     "duration": 0.008498,
     "end_time": "2024-04-20T18:37:08.063514",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.055016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You could also add some other kinds of guidelines. You could ask, or give a rubric, like a rubric for an exam or essay grading. You could use that format and say, does this use a friendly tone and maybe outline some of your brand guidelines.\n",
    "\n",
    "So let's add our customer message and the product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f7306a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:08.082476Z",
     "iopub.status.busy": "2024-04-20T18:37:08.082092Z",
     "iopub.status.idle": "2024-04-20T18:37:08.088538Z",
     "shell.execute_reply": "2024-04-20T18:37:08.087515Z"
    },
    "papermill": {
     "duration": 0.018931,
     "end_time": "2024-04-20T18:37:08.090746",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.071815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_message = f\"\"\"\n",
    "tell me about the smartx pro phone and \\\n",
    "the fotosnap camera, the dslr one. \\\n",
    "Also tell me about your tvs\"\"\"\n",
    "\n",
    "product_information = \"\"\"{ \"name\": \"SmartX ProPhone\", \"category\": \"Smartphones and Accessories\", \"brand\": \"SmartX\", \"model_number\": \"SX-PP10\", \"warranty\": \"1 year\", \"rating\": 4.6, \"features\": [ \"6.1-inch display\", \"128GB storage\", \"12MP dual camera\", \"5G\" ], \"description\": \"A powerful smartphone with advanced camera features.\", \"price\": 899.99 } { \"name\": \"FotoSnap DSLR Camera\", \"category\": \"Cameras and Camcorders\", \"brand\": \"FotoSnap\", \"model_number\": \"FS-DSLR200\", \"warranty\": \"1 year\", \"rating\": 4.7, \"features\": [ \"24.2MP sensor\", \"1080p video\", \"3-inch LCD\", \"Interchangeable lenses\" ], \"description\": \"Capture stunning photos and videos with this versatile DSLR camera.\", \"price\": 599.99 } { \"name\": \"CineView 4K TV\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"CineView\", \"model_number\": \"CV-4K55\", \"warranty\": \"2 years\", \"rating\": 4.8, \"features\": [ \"55-inch display\", \"4K resolution\", \"HDR\", \"Smart TV\" ], \"description\": \"A stunning 4K TV with vibrant colors and smart features.\", \"price\": 599.99 } { \"name\": \"SoundMax Home Theater\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"SoundMax\", \"model_number\": \"SM-HT100\", \"warranty\": \"1 year\", \"rating\": 4.4, \"features\": [ \"5.1 channel\", \"1000W output\", \"Wireless subwoofer\", \"Bluetooth\" ], \"description\": \"A powerful home theater system for an immersive audio experience.\", \"price\": 399.99 } { \"name\": \"CineView 8K TV\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"CineView\", \"model_number\": \"CV-8K65\", \"warranty\": \"2 years\", \"rating\": 4.9, \"features\": [ \"65-inch display\", \"8K resolution\", \"HDR\", \"Smart TV\" ], \"description\": \"Experience the future of television with this stunning 8K TV.\", \"price\": 2999.99 } { \"name\": \"SoundMax Soundbar\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"SoundMax\", \"model_number\": \"SM-SB50\", \"warranty\": \"1 year\", \"rating\": 4.3, \"features\": [ \"2.1 channel\", \"300W output\", \"Wireless subwoofer\", \"Bluetooth\" ], \"description\": \"Upgrade your TV's audio with this sleek and powerful soundbar.\", \"price\": 199.99 } { \"name\": \"CineView OLED TV\", \"category\": \"Televisions and Home Theater Systems\", \"brand\": \"CineView\", \"model_number\": \"CV-OLED55\", \"warranty\": \"2 years\", \"rating\": 4.7, \"features\": [ \"55-inch display\", \"4K resolution\", \"HDR\", \"Smart TV\" ], \"description\": \"Experience true blacks and vibrant colors with this OLED TV.\", \"price\": 1499.99 }\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22413e72",
   "metadata": {
    "papermill": {
     "duration": 0.00859,
     "end_time": "2024-04-20T18:37:08.108014",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.099424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Now we will define the comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d133ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:08.127557Z",
     "iopub.status.busy": "2024-04-20T18:37:08.126676Z",
     "iopub.status.idle": "2024-04-20T18:37:08.132446Z",
     "shell.execute_reply": "2024-04-20T18:37:08.130793Z"
    },
    "papermill": {
     "duration": 0.01789,
     "end_time": "2024-04-20T18:37:08.134586",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.116696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_a_pair = f\"\"\"\n",
    "Customer message: ```{customer_message}```\n",
    "Product information: ```{product_information}```\n",
    "Agent response: ```{final_response_to_customer}```\n",
    "\n",
    "Does the response use the retrieved information correctly?\n",
    "Does the response sufficiently answer the question\n",
    "\n",
    "Output Y or N\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ec427",
   "metadata": {
    "papermill": {
     "duration": 0.008476,
     "end_time": "2024-04-20T18:37:08.151545",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.143069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Finally, we will format this into a messages list and get the response from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ef889ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:08.169797Z",
     "iopub.status.busy": "2024-04-20T18:37:08.169445Z",
     "iopub.status.idle": "2024-04-20T18:37:08.735890Z",
     "shell.execute_reply": "2024-04-20T18:37:08.734748Z"
    },
    "papermill": {
     "duration": 0.578375,
     "end_time": "2024-04-20T18:37:08.738112",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.159737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': q_a_pair}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages, max_tokens=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48bae9",
   "metadata": {
    "papermill": {
     "duration": 0.008827,
     "end_time": "2024-04-20T18:37:08.756329",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.747502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So the model says yes, the product information is correct and the question is answered sufficiently.¬†\n",
    "Let's try another response which is \"**Life is like a box of chocolates**.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7031657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:08.775429Z",
     "iopub.status.busy": "2024-04-20T18:37:08.775034Z",
     "iopub.status.idle": "2024-04-20T18:37:08.779601Z",
     "shell.execute_reply": "2024-04-20T18:37:08.778454Z"
    },
    "papermill": {
     "duration": 0.016665,
     "end_time": "2024-04-20T18:37:08.781854",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.765189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "another_response = \"life is like a box of chocolates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3e49c",
   "metadata": {
    "papermill": {
     "duration": 0.008736,
     "end_time": "2024-04-20T18:37:08.799606",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.790870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So let's add our message to do with the output checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cddbae9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-20T18:37:08.819012Z",
     "iopub.status.busy": "2024-04-20T18:37:08.818345Z",
     "iopub.status.idle": "2024-04-20T18:37:09.358505Z",
     "shell.execute_reply": "2024-04-20T18:37:09.357213Z"
    },
    "papermill": {
     "duration": 0.552485,
     "end_time": "2024-04-20T18:37:09.360884",
     "exception": false,
     "start_time": "2024-04-20T18:37:08.808399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\n"
     ]
    }
   ],
   "source": [
    "q_a_pair = f\"\"\"\n",
    "Customer message: ```{customer_message}```\n",
    "Product information: ```{product_information}```\n",
    "Agent response: ```{another_response}```\n",
    "\n",
    "Does the response use the retrieved information correctly?\n",
    "Does the response sufficiently answer the question?\n",
    "\n",
    "Output Y or N\n",
    "\"\"\"\n",
    "messages = [\n",
    "    {'role': 'system', 'content': system_message},\n",
    "    {'role': 'user', 'content': q_a_pair}\n",
    "]\n",
    "\n",
    "response = get_completion_from_messages(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f2ab4",
   "metadata": {
    "papermill": {
     "duration": 0.009103,
     "end_time": "2024-04-20T18:37:09.379326",
     "exception": false,
     "start_time": "2024-04-20T18:37:09.370223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model has determined that this does not sufficiently answer the question or use the retrieved information.\n",
    "The question we used here \"Does the response use the retrieved information correctly? Does the response sufficiently answer the question?\" is a good prompt to use if you want to make sure that the model isn't hallucinating and is not making up things that aren't true.¬†\n",
    "\n",
    "As you can see, the model can provide feedback on the quality of a generated output, and you can use this feedback to decide whether to present the output to the user or to generate a new response.¬†\n",
    "\n",
    "You could even experiment with generating multiple model responses per user query, and then having the model choose the best one to show the user.\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7238719",
   "metadata": {
    "papermill": {
     "duration": 0.008982,
     "end_time": "2024-04-20T18:37:09.397849",
     "exception": false,
     "start_time": "2024-04-20T18:37:09.388867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " In general, it is advisable to use the moderation API to validate outputs, as it promotes responsible and ethical usage. While there is a possibility of obtaining immediate feedback by asking the model to evaluate itself in certain cases, it appears to be largely unnecessary, particularly with advanced models such as GPT-4.\n",
    " \n",
    "From my experience, this method is not frequently utilized in practice. Additionally, implementing it would result in increased system delay and expenses, as it requires an extra model call and additional tokens.\n",
    "\n",
    "If achieving an extremely low error rate of 0.00001% is crucial for your Apple product, then this approach may be worth considering. However, overall, I would not recommend adopting it as a standard practice in general circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd17bba",
   "metadata": {
    "papermill": {
     "duration": 0.009043,
     "end_time": "2024-04-20T18:37:09.416099",
     "exception": false,
     "start_time": "2024-04-20T18:37:09.407056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"box-shadow: rgba(240, 46, 170, 0.4) -5px 5px inset, rgba(240, 46, 170, 0.3) -10px 10px inset, rgba(240, 46, 170, 0.2) -15px 15px inset, rgba(240, 46, 170, 0.1) -20px 20px inset, rgba(240, 46, 170, 0.05) -25px 25px inset; padding:20px; font-size:30px; font-family: consolas; display:fill; border-radius:15px; color: rgba(240, 46, 170, 0.7)\"> <b> ‡ºº‚Å† ‚Å†„Å§‚Å† ‚Å†‚óï‚Å†‚Äø‚Å†‚óï‚Å† ‚Å†‡ºΩ‚Å†„Å§ Thank You!</b></div>\n",
    "\n",
    "<p style=\"font-family:verdana; color:rgb(34, 34, 34); font-family: consolas; font-size: 16px;\"> üíå Thank you for taking the time to read through my notebook. I hope you found it interesting and informative. If you have any feedback or suggestions for improvement, please don't hesitate to let me know in the comments. <br><br> üöÄ If you liked this notebook, please consider upvoting it so that others can discover it too. Your support means a lot to me, and it helps to motivate me to create more content in the future. <br><br> ‚ù§Ô∏è Once again, thank you for your support, and I hope to see you again soon!</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.660294,
   "end_time": "2024-04-20T18:37:09.945647",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-20T18:36:47.285353",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
