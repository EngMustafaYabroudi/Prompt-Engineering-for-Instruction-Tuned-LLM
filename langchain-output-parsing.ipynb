{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7be3cc2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.006316,
     "end_time": "2025-03-23T15:11:38.592437",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.586121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center style=\"font-family: consolas; font-size: 32px; font-weight: bold;\">  Hands-On LangChain for LLM Applications Development: Output Parsing </center>\n",
    "\n",
    "***\n",
    "\n",
    "When developing a complex application with a Language Model (LLM), it’s common to specify the desired output format, such as JSON, and designate particular keys for organizing the data. \n",
    "\n",
    "Let’s consider the chain of thought reasoning method as an illustrative example. In this method, the LLM’s thinking process is represented by distinct stages: “thought” indicates the reasoning process, “action” denotes the subsequent action taken, and “observation” reflects the learning acquired from that action, and so forth. By crafting a prompt that directs the LLM to utilize these specific keywords (thought, action, observation), we can effectively guide its cognitive process. \n",
    "\n",
    "In this article, we will cover coupling the prompt with a parser that allows for the extraction of text associated with certain keywords from the LLM’s output. This combined approach offers a streamlined means of specifying input for the LLM and accurately interpreting its output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42b1d9",
   "metadata": {
    "papermill": {
     "duration": 0.005104,
     "end_time": "2025-03-23T15:11:38.602981",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.597877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 1. Parsing Output Using LangChain Prompt Templates </b></div>\n",
    "\n",
    "\n",
    "Let's start with an example to clarify the output parsing concept. Let’s take a look at how you can have an LLM output JSON, and use LangChain to parse that output. \n",
    "\n",
    "In this example, we will extract information from a product review and format that output in a JSON format. Here’s an example of how you would like the output formatted. Technically, this is a Python dictionary, where whether or not the product is a gift, maps to false, the number of days it took to deliver was five, and the price value was pretty affordable. So this is one example of a desired output:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef1b3ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:11:38.615167Z",
     "iopub.status.busy": "2025-03-23T15:11:38.614796Z",
     "iopub.status.idle": "2025-03-23T15:11:38.625101Z",
     "shell.execute_reply": "2025-03-23T15:11:38.624109Z"
    },
    "papermill": {
     "duration": 0.01902,
     "end_time": "2025-03-23T15:11:38.627225",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.608205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = {\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acdf4a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:11:38.640357Z",
     "iopub.status.busy": "2025-03-23T15:11:38.639321Z",
     "iopub.status.idle": "2025-03-23T15:11:38.646717Z",
     "shell.execute_reply": "2025-03-23T15:11:38.645629Z"
    },
    "papermill": {
     "duration": 0.015948,
     "end_time": "2025-03-23T15:11:38.648747",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.632799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pretty affordable!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get(\"price_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701584f8",
   "metadata": {
    "papermill": {
     "duration": 0.005231,
     "end_time": "2025-03-23T15:11:38.659540",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.654309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here is an example of a customer review, as well as a template and we want to get the output as JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "665d92a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:11:38.672125Z",
     "iopub.status.busy": "2025-03-23T15:11:38.671773Z",
     "iopub.status.idle": "2025-03-23T15:11:38.677610Z",
     "shell.execute_reply": "2025-03-23T15:11:38.676444Z"
    },
    "papermill": {
     "duration": 0.015018,
     "end_time": "2025-03-23T15:11:38.679954",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.664936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3676dc",
   "metadata": {
    "papermill": {
     "duration": 0.005157,
     "end_time": "2025-03-23T15:11:38.691067",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.685910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So, the review template asks the LLM to take as input a customer review extract these three fields and then format the output as JSON with the following keys. \n",
    "\n",
    "So here’s how you can wrap this in LangChain. First, we will import the chat prompt template. Then we will have the prompt templates created from the review template up on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f25b7e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:11:38.703574Z",
     "iopub.status.busy": "2025-03-23T15:11:38.703203Z",
     "iopub.status.idle": "2025-03-23T15:12:27.055884Z",
     "shell.execute_reply": "2025-03-23T15:12:27.054506Z"
    },
    "papermill": {
     "duration": 48.36187,
     "end_time": "2025-03-23T15:12:27.058426",
     "exception": false,
     "start_time": "2025-03-23T15:11:38.696556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\r\n",
      "  Downloading langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain)\r\n",
      "  Downloading langchain_core-0.3.47-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain)\r\n",
      "  Downloading langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\r\n",
      "  Downloading langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\r\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (8.2.3)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\r\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.45->langchain)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\r\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\r\n",
      "  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\r\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\r\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\r\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\r\n",
      "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<1.0.0,>=0.3.45->langchain)\r\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.4)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.0)\r\n",
      "Downloading langchain-0.3.21-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_core-0.3.47-py3-none-any.whl (417 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.1/417.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\r\n",
      "Downloading langsmith-0.3.18-py3-none-any.whl (351 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m351.9/351.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\r\n",
      "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: zstandard, typing-extensions, packaging, orjson, requests-toolbelt, pydantic-core, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\r\n",
      "  Attempting uninstall: zstandard\r\n",
      "    Found existing installation: zstandard 0.22.0\r\n",
      "    Uninstalling zstandard-0.22.0:\r\n",
      "      Successfully uninstalled zstandard-0.22.0\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.9.0\r\n",
      "    Uninstalling typing_extensions-4.9.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.9.0\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: orjson\r\n",
      "    Found existing installation: orjson 3.9.10\r\n",
      "    Uninstalling orjson-3.9.10:\r\n",
      "      Successfully uninstalled orjson-3.9.10\r\n",
      "  Attempting uninstall: requests-toolbelt\r\n",
      "    Found existing installation: requests-toolbelt 0.10.1\r\n",
      "    Uninstalling requests-toolbelt-0.10.1:\r\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\r\n",
      "  Attempting uninstall: pydantic-core\r\n",
      "    Found existing installation: pydantic_core 2.14.6\r\n",
      "    Uninstalling pydantic_core-2.14.6:\r\n",
      "      Successfully uninstalled pydantic_core-2.14.6\r\n",
      "  Attempting uninstall: pydantic\r\n",
      "    Found existing installation: pydantic 2.5.3\r\n",
      "    Uninstalling pydantic-2.5.3:\r\n",
      "      Successfully uninstalled pydantic-2.5.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.9.3 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\r\n",
      "jupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed langchain-0.3.21 langchain-core-0.3.47 langchain-text-splitters-0.3.7 langsmith-0.3.18 orjson-3.10.15 packaging-24.2 pydantic-2.10.6 pydantic-core-2.27.2 requests-toolbelt-1.0.0 typing-extensions-4.12.2 zstandard-0.23.0\r\n",
      "Collecting langchain_community\r\n",
      "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.47)\r\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.21)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.31.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.4)\r\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\r\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.3.18)\r\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\r\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\r\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.10.6)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.12.2)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.27.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\r\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\r\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\r\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.2.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.5)\r\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.0)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (2.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.27.2)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.2.0)\r\n",
      "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\r\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\r\n",
      "Installing collected packages: httpx-sse, pydantic-settings, langchain_community\r\n",
      "Successfully installed httpx-sse-0.4.0 langchain_community-0.3.20 pydantic-settings-2.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3d0ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:27.078560Z",
     "iopub.status.busy": "2025-03-23T15:12:27.078102Z",
     "iopub.status.idle": "2025-03-23T15:12:38.760377Z",
     "shell.execute_reply": "2025-03-23T15:12:38.758988Z"
    },
    "papermill": {
     "duration": 11.695394,
     "end_time": "2025-03-23T15:12:38.762968",
     "exception": false,
     "start_time": "2025-03-23T15:12:27.067574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c0a481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:38.782916Z",
     "iopub.status.busy": "2025-03-23T15:12:38.782192Z",
     "iopub.status.idle": "2025-03-23T15:12:39.996146Z",
     "shell.execute_reply": "2025-03-23T15:12:39.994777Z"
    },
    "papermill": {
     "duration": 1.226232,
     "end_time": "2025-03-23T15:12:39.998243",
     "exception": false,
     "start_time": "2025-03-23T15:12:38.772011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] input_types={} partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93233948",
   "metadata": {
    "papermill": {
     "duration": 0.008624,
     "end_time": "2025-03-23T15:12:40.016227",
     "exception": false,
     "start_time": "2025-03-23T15:12:40.007603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s create the messages to pass to the OpenAI, endpoint. Create the OpenAI endpoint, call that endpoint, and then let’s print out the response. I encourage you to pause the video and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cd6afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:40.035967Z",
     "iopub.status.busy": "2025-03-23T15:12:40.035486Z",
     "iopub.status.idle": "2025-03-23T15:12:40.800248Z",
     "shell.execute_reply": "2025-03-23T15:12:40.799041Z"
    },
    "papermill": {
     "duration": 0.777569,
     "end_time": "2025-03-23T15:12:40.802764",
     "exception": false,
     "start_time": "2025-03-23T15:12:40.025195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "openai.api_key = user_secrets.get_secret(\"openai_api\")\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=openai.api_key,\n",
    ")\n",
    "\n",
    "llm_model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2e7e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:40.822715Z",
     "iopub.status.busy": "2025-03-23T15:12:40.822320Z",
     "iopub.status.idle": "2025-03-23T15:12:42.298777Z",
     "shell.execute_reply": "2025-03-23T15:12:42.297574Z"
    },
    "papermill": {
     "duration": 1.489188,
     "end_time": "2025-03-23T15:12:42.301104",
     "exception": false,
     "start_time": "2025-03-23T15:12:40.811916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/1190519107.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=openai.api_key)\n",
      "/tmp/ipykernel_18/1190519107.py:5: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chat(messages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"gift\": true,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\", \"I think it's worth it for the extra features\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model, openai_api_key=openai.api_key)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a6338",
   "metadata": {
    "papermill": {
     "duration": 0.009039,
     "end_time": "2025-03-23T15:12:42.319560",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.310521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It says the gift is true, the delivery day is 2, and the price value also looks pretty accurate. But note that if we check the type of the response, this is a string. So it looks like JSON and has key-value pairs, but it’s not a dictionary. This is just one long string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8901c2b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.341370Z",
     "iopub.status.busy": "2025-03-23T15:12:42.340627Z",
     "iopub.status.idle": "2025-03-23T15:12:42.348797Z",
     "shell.execute_reply": "2025-03-23T15:12:42.347403Z"
    },
    "papermill": {
     "duration": 0.022648,
     "end_time": "2025-03-23T15:12:42.351475",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.328827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac0cd4",
   "metadata": {
    "papermill": {
     "duration": 0.010882,
     "end_time": "2025-03-23T15:12:42.373303",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.362421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So what I’d like to do is go to the response content and get the value from the gift key which should be true, but if I run this, this should generate an error because, well, this is a string. This is not a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733ee891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.400376Z",
     "iopub.status.busy": "2025-03-23T15:12:42.399953Z",
     "iopub.status.idle": "2025-03-23T15:12:42.405195Z",
     "shell.execute_reply": "2025-03-23T15:12:42.404151Z"
    },
    "papermill": {
     "duration": 0.01944,
     "end_time": "2025-03-23T15:12:42.407620",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.388180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "\n",
    "# response.content.get('gift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ab0451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.434124Z",
     "iopub.status.busy": "2025-03-23T15:12:42.433222Z",
     "iopub.status.idle": "2025-03-23T15:12:42.439805Z",
     "shell.execute_reply": "2025-03-23T15:12:42.438787Z"
    },
    "papermill": {
     "duration": 0.020951,
     "end_time": "2025-03-23T15:12:42.441758",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.420807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df710d50",
   "metadata": {
    "papermill": {
     "duration": 0.008961,
     "end_time": "2025-03-23T15:12:42.459993",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.451032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s see how we will use LangChain’s parser to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8366f5",
   "metadata": {
    "papermill": {
     "duration": 0.008922,
     "end_time": "2025-03-23T15:12:42.478225",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.469303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px inset, rgb(51, 51, 51) 0px 0px 0px 3px inset; padding:20px; font-size:32px; font-family: consolas; text-align:center; display:fill; border-radius:15px;  color:rgb(34, 34, 34);\"> <b> 2. Parse the LLM Output String into a Python Dictionary </b></div>\n",
    "\n",
    "\n",
    "To parse the output into json format and make its type Python dict not string we will start with importing the response schema and structured output parser from LangChain. \n",
    "\n",
    "I am going to tell it what I wanted to parse by specifying these response schemas. So the gif schema, delivery days schema, and price value schema, here are their description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657c204a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.499309Z",
     "iopub.status.busy": "2025-03-23T15:12:42.498310Z",
     "iopub.status.idle": "2025-03-23T15:12:42.556584Z",
     "shell.execute_reply": "2025-03-23T15:12:42.555650Z"
    },
    "papermill": {
     "duration": 0.071269,
     "end_time": "2025-03-23T15:12:42.558990",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.487721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "\n",
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a963ad",
   "metadata": {
    "papermill": {
     "duration": 0.012983,
     "end_time": "2025-03-23T15:12:42.584976",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.571993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that I’ve specified the schema for these LangChain can give you the prompt itself by having the output parser tell you what instructions it wants you to send to the LLM. So if I were to print format instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d7b1172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.614266Z",
     "iopub.status.busy": "2025-03-23T15:12:42.613834Z",
     "iopub.status.idle": "2025-03-23T15:12:42.620881Z",
     "shell.execute_reply": "2025-03-23T15:12:42.619425Z"
    },
    "papermill": {
     "duration": 0.025007,
     "end_time": "2025-03-23T15:12:42.623801",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.598794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf3b058",
   "metadata": {
    "papermill": {
     "duration": 0.010654,
     "end_time": "2025-03-23T15:12:42.648027",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.637373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This is a precise set of instructions for the LLM that will cause it to generate an output that the output parser can process. So here’s the new review template and the review template includes the format instructions that LangChain generated.\n",
    "\n",
    "We can create a prompt from the review template too, and then create the messages that will pass to the OpenAI endpoint. If you want, you can take a look at the actual prompt, which gives the instructions to extract the fields gift, delivery days, and price value, here’s the text, and then here are the formatting instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb593116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.674745Z",
     "iopub.status.busy": "2025-03-23T15:12:42.673884Z",
     "iopub.status.idle": "2025-03-23T15:12:42.681002Z",
     "shell.execute_reply": "2025-03-23T15:12:42.679502Z"
    },
    "papermill": {
     "duration": 0.023466,
     "end_time": "2025-03-23T15:12:42.684075",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.660609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4273bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.706780Z",
     "iopub.status.busy": "2025-03-23T15:12:42.706353Z",
     "iopub.status.idle": "2025-03-23T15:12:42.712953Z",
     "shell.execute_reply": "2025-03-23T15:12:42.711911Z"
    },
    "papermill": {
     "duration": 0.019482,
     "end_time": "2025-03-23T15:12:42.715011",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.695529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\ntext: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife\\'s anniversary present. I think my wife liked it so much she was speechless. So far I\\'ve been the only one using it, and I\\'ve been using it every other morning to clear the leaves on our lawn. It\\'s slightly more expensive than the other leaf blowers out there, but I think it\\'s worth it for the extra features.\\n\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\\n\\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\\n\\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\\n}\\n```\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b40080e",
   "metadata": {
    "papermill": {
     "duration": 0.009309,
     "end_time": "2025-03-23T15:12:42.734003",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.724694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, if we call the OpenAI endpoint, let’s take a look at what response we got. It is now this, and now if we use the output parser that we created earlier, you can then parse this into an output dictionary, which if I print, looks like this. \n",
    "\n",
    "Notice that this is of type dictionary, not a string, which is why I can now extract the value associated with the key gift and get true, or the value associated with delivery days and get two, or you can also extract the value associated with price value. So this is a nifty way to take your LLM output and parse it into a Python dictionary, to make the output easier to use in downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e76ebbd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-23T15:12:42.756041Z",
     "iopub.status.busy": "2025-03-23T15:12:42.755641Z",
     "iopub.status.idle": "2025-03-23T15:12:42.760305Z",
     "shell.execute_reply": "2025-03-23T15:12:42.759294Z"
    },
    "papermill": {
     "duration": 0.018435,
     "end_time": "2025-03-23T15:12:42.762695",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.744260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = chat(messages)\n",
    "# output_dict = output_parser.parse(response.content)\n",
    "# output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d523b",
   "metadata": {
    "papermill": {
     "duration": 0.009451,
     "end_time": "2025-03-23T15:12:42.782165",
     "exception": false,
     "start_time": "2025-03-23T15:12:42.772714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# <div style=\"box-shadow: rgba(240, 46, 170, 0.4) -5px 5px inset, rgba(240, 46, 170, 0.3) -10px 10px inset, rgba(240, 46, 170, 0.2) -15px 15px inset, rgba(240, 46, 170, 0.1) -20px 20px inset, rgba(240, 46, 170, 0.05) -25px 25px inset; padding:20px; font-size:30px; font-family: consolas; display:fill; border-radius:15px; color: rgba(240, 46, 170, 0.7)\"> <b> ༼⁠ ⁠つ⁠ ⁠◕⁠‿⁠◕⁠ ⁠༽⁠つ Thank You!</b></div>\n",
    "​\n",
    "<p style=\"font-family:verdana; color:rgb(34, 34, 34); font-family: consolas; font-size: 16px;\"> 💌 Thank you for taking the time to read through my notebook. I hope you found it interesting and informative. If you have any feedback or suggestions for improvement, please don't hesitate to let me know in the comments. <br><br> 🚀 If you liked this notebook, please consider upvoting it so that others can discover it too. Your support means a lot to me, and it helps to motivate me to create more content in the future. <br><br> ❤️ Once again, thank you for your support, and I hope to see you again soon!</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 68.162479,
   "end_time": "2025-03-23T15:12:43.513374",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-23T15:11:35.350895",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
